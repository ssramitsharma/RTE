{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity\n",
    "\n",
    "* Semantic similarity is a metric defined over a set of documents or terms, where the idea of distance between them is based on the likeness of their meaning \n",
    "* The term semantic similarity is often confused with semantic relatedness. \n",
    "* Semantic relatedness includes any relation between two terms, while semantic similarity only includes \"is a\" relations. For example, \"car\" is similar to \"bus\", but is also related to \"road\" and \"driving\".\n",
    "\n",
    "* Reference: Wikipaedia\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between dog and crow =  0.201595276747\n",
      "similarity between piegon and crow =  0.246586903236\n",
      "similarity between friend and amigo =  0.818362624271\n"
     ]
    }
   ],
   "source": [
    "import sematch\n",
    "from sematch.semantic.similarity import WordNetSimilarity\n",
    "wns = WordNetSimilarity()\n",
    "print'similarity between dog and crow = ' ,wns.word_similarity('dog', 'crow', 'li')\n",
    "print'similarity between piegon and crow = ', wns.word_similarity('pigeon', 'crow', 'li')\n",
    "print'similarity between friend and amigo = ', wns.word_similarity('friend', 'amigo', 'li')\n",
    "# Reference http://gsi-upm.github.io/sematch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Automatic Short answer grading\n",
    "* This method assesses a text by computing a score based on  explicit  word-to-word  match  between  the  student’s  answer and teacher’s answer (i.e. reference)\n",
    "* If more than one reference is available, the matching similarity is scored against each reference independently and the best scoring pair is used to find the final score\n",
    "* Exact module:This module will match unigrams only if their surface forms match. (doubt)\n",
    "\n",
    "Note:In the fields of computational linguistics and probability, an n-gram is a contiguous sequence of n items from a given sequence of text or speech. The items can be phonemes, syllables, letters, words or base pairs according to the application. The n-grams typically are collected from a text or speech corpus. When the items are words, n-grams may also be called shingles.\n",
    "An n-gram of size 1 is referred to as a \"unigram\"; size 2 is a \"bigram\" (or, less commonly, a \"digram\"); size 3 is a \"trigram\". Larger sizes are sometimes referred to by the value of n in modern language, e.g., \"four-gram\", \"five-gram\", and so on.\n",
    "* Stemming module: This matches two unigrams to each other if they are identical after being passed through the Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Heuristics Rule based module:This module maps two unigrams to each other if they share the same baseform basedon some heuristics rules. \n",
    "https://pythonprogramming.net/stemming-nltk-tutorial/\n",
    "* Rule 1 - WordNet synonym match:if two unigrams are matched it shows that they both will have same parts of speechand belongs to the same synset in WordNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'alter',\n",
       " u'alteration',\n",
       " u'change',\n",
       " u'commute',\n",
       " u'convert',\n",
       " u'deepen',\n",
       " u'exchange',\n",
       " u'interchange',\n",
       " u'modification',\n",
       " u'modify',\n",
       " u'shift',\n",
       " u'switch',\n",
       " u'transfer',\n",
       " u'variety',\n",
       " u'vary'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = wordnet.synsets('text')\n",
    "lemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "synonyms = wordnet.synsets('change')\n",
    "set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "set([u'interchange', u'convert', u'variety', u'vary', u'exchange', u'modify', u'alteration', u'switch', u'commute', u'shift', u'modification', u'deepen', u'transfer', u'alter', u'change'])\n",
    "#Reference https://stackoverflow.com/questions/19258652/how-to-get-synonyms-from-nltk-wordnet-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rule 2 - Numeric value match:The numeric value features to each part of text inferred to correspond to a numeric value. (Eg.“7th”is aligned to “seventh”)\n",
    "(didn't find any library which would be helpful in this matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'seven'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from num2words import num2words\n",
    "num2words(7)\n",
    "# Reference: https://pypi.python.org/pypi/num2words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rule  3  -  Acronym  match:  It aligns  pairs  of  node  with  the  properties of capitalized letters and the letters c orrespond to the  first characters of some multiword. (Eg. “NLP” is a ligned with   “Natural Language Processing”) \n",
    "\n",
    "(Didn't find any library for matching acronyms , hence the necessary acronyms need to be defined manually)\n",
    "\n",
    "* Rule 4 - Derivational form match:This Rule is to align words which have the same root form (or have a synonym with the same root form) and which have similar semantic meaning, but which may belong to different syntactic categories.\n",
    "\n",
    "(for synonyms , we can use the above example\n",
    "\n",
    "for roots we can use Porterstemmer\n",
    "\n",
    "to find similarity we can use sematch\n",
    "\n",
    "to find synactic categories we can use parts of speech in nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU (bilingual evaluation understudy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454801904703\n"
     ]
    }
   ],
   "source": [
    "#Reference https://stackoverflow.com/questions/32395880/calculate-bleu-score-in-python\n",
    "import nltk\n",
    "\n",
    "hypothesis = ['It', 'is', 'a', 'cat', 'at', 'room']\n",
    "reference1 = ['It', 'is', 'a', 'cat', 'inside', 'the', 'room']\n",
    "reference2 = ['It', 'is', 'a', 'cat', 'in', 'the', 'room']\n",
    "#there may be several references\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference1,reference2], hypothesis)\n",
    "print BLEUscore\n",
    "#Reference: https://stackoverflow.com/questions/32395880/calculate-bleu-score-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AI assisted Grading\n",
    "* The AI isn’t used to directly grade the papers; rather, it turns grading into an automated, highly repeatable exercise by learning to identify and group answers, and thus treat them as batches.\n",
    "* Using an interface similar to a photo manager, instructors ensure that the automatically suggested answer groups are correct, and then score each answer with a rubric.\n",
    "* In this way, input from users lets the AI continually improve its future predictions.\n",
    "* “Traditionally, if you were to give a test to 100 students and they all write the correct answer, you would have to go through all 100 and mark them correct,” said Karayev. “With AI-assisted grading, you could grade one answer and it would apply to all 100 students.”\n",
    "* Karayev said the AI feature attempts to address three challenges: identifying question types, such as multiple choice, fill in the blank or written answers; distinguishing between different written marks, including when a student crosses out a multiple choice answer and chooses another; and, perhaps the toughest of the three, recognizing handwriting.\n",
    "\n",
    "* Reference\n",
    "https://blog.writelab.com/blog/ai-assisted-grading-an-english-teachers-dream-come-true\n",
    "https://blogs.nvidia.com/blog/2016/09/02/gradescope-brings-ai-to-grading/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
